{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "lab03_build_img_classifier_functional_API.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsTWNrUkHlz"
      },
      "source": [
        "# Introduction\n",
        "In this notebook, we are using the Keras API in Tensorflow 2.X to build an image classifier to recognize Handwritten digits using the Mnist data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9jkOW0BkFoO"
      },
      "source": [
        "# Loading Tensorflow and checking the version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whClKcLBkVLV",
        "outputId": "7cc21638-63f0-4e68-867f-0dba5f4f3014"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72OsafxTkePO"
      },
      "source": [
        "- If not installed, uncomment the following cell. \n",
        "- **PS:** using pip not conda as everything on colab is prepared for you (cuda)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5w4z1qkfCn"
      },
      "source": [
        "#!pip install tensorflow==2.5.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAUyfyCGkosR"
      },
      "source": [
        "# Data Loading and exploring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoR7D5Oksiu",
        "outputId": "a4d4c8d8-df98-452e-8e56-cb80fe3d606f"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(training_images, training_labels),(testing_images, testing_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Lgse1mloXb",
        "outputId": "420772dd-e8a9-4f4d-d1e7-5d70759953e1"
      },
      "source": [
        "print(\"The number of training images is {}\".format(training_images.shape[0]))\n",
        "print(\"The number of testing images is {}\".format(testing_images.shape[0]))\n",
        "print(\"The shape of an image is {}X{}\".format(training_images.shape[1],\n",
        "                                              training_images.shape[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The number of training images is 60000\n",
            "The number of testing images is 10000\n",
            "The shape of an image is 28X28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJYUk6GrlGmp"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "YboJdayulamy",
        "outputId": "c1eb211d-651e-4509-a9f6-b57214df34e5"
      },
      "source": [
        "img_number = random.randint(0, training_images.shape[0])\n",
        "plt.imshow(training_images[img_number])\n",
        "print(training_labels[img_number])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFk7rY5mWpo"
      },
      "source": [
        "All of the pixels values are between 0 and 255. If we are training a neural network, for various reasons it's easier that all values are between 0 and 1.\n",
        "\n",
        "This can be done using `normalizing`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kb7d3LjcnB58"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "testing_images = testing_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXQ0kOROnflN"
      },
      "source": [
        "# Defining the model using **Sequential** API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9rkDIjdngXM"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pQNcXJnoQu"
      },
      "source": [
        "model = Sequential([Flatten(input_shape=(28,28)), \n",
        "                    Dense(128, activation=tf.nn.relu), \n",
        "                    Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlYUZ-Ag1_mm",
        "outputId": "50a334ad-1588-4f1d-b6ff-e42f692c552b"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmI9EO-8n9U4"
      },
      "source": [
        "Define the **optimizer** and the **loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVS9wyG9n_cE"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-li45MojR6"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94PtEBCwog6s",
        "outputId": "09e3b1ea-42f1-410f-e40c-edd33603ec98"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 7s 2ms/step - loss: 0.2582 - accuracy: 0.9260\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1118 - accuracy: 0.9679\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0783 - accuracy: 0.9762\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0592 - accuracy: 0.9822\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0439 - accuracy: 0.9861\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faae3fbec10>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qQXQdWnolTu"
      },
      "source": [
        "Evaluate the model on the test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_Ium0nooci",
        "outputId": "3295725b-d1dd-4b2c-cccf-a2db6ad066a6"
      },
      "source": [
        "evaluation = model.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0835 - accuracy: 0.9743\n",
            "Accuracy on the testing images is 97.43000268936157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEGvoPkLyfcq"
      },
      "source": [
        "# Defining the model using **Functional** API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onLgl9jlyhyx"
      },
      "source": [
        "from tensorflow.keras import Model, Input\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RsBtjjgymem"
      },
      "source": [
        "inputs  = Input(shape=(28,28))\n",
        "x       = Flatten()(inputs)\n",
        "x       = Dense(128, activation=tf.nn.relu)(x)\n",
        "outputs = Dense(10, activation=tf.nn.softmax)(x)\n",
        "\n",
        "model_func = Model(inputs=inputs, outputs=outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnEpk6i10HMd"
      },
      "source": [
        "model_func.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHvLRBU00K1q",
        "outputId": "de99e465-421c-4cdc-ce7e-33e5730d86f0"
      },
      "source": [
        "model_func.fit(training_images, training_labels, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2646 - accuracy: 0.9240\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1158 - accuracy: 0.9661\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0789 - accuracy: 0.9766\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0588 - accuracy: 0.9819\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0467 - accuracy: 0.9856\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faae3eade50>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWXUQ4tS0Pe2",
        "outputId": "79d28e7d-023c-4c9d-d935-4c72290dc831"
      },
      "source": [
        "evaluation = model_func.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9729\n",
            "Accuracy on the testing images is 97.28999733924866\n"
          ]
        }
      ]
    }
  ]
}