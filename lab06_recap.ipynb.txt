{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab06_recap.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIsTWNrUkHlz"
      },
      "source": [
        "# Introduction\n",
        "In this notebook, we are using the Keras API in Tensorflow 2.X to build an image classifier to recognize Handwritten digits using the Mnist data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9jkOW0BkFoO"
      },
      "source": [
        "# Loading Tensorflow and checking the version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whClKcLBkVLV",
        "outputId": "e9a11357-b46b-4ab4-b435-5832c377ec72"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72OsafxTkePO"
      },
      "source": [
        "- If not installed, uncomment the following cell. \n",
        "- **PS:** using pip not conda as everything on colab is prepared for you (cuda)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL5w4z1qkfCn"
      },
      "source": [
        "#!pip install tensorflow==2.5.0 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAUyfyCGkosR"
      },
      "source": [
        "# Data Loading and exploring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuoR7D5Oksiu",
        "outputId": "40a5fd73-41a8-4fa5-dcab-81e54e28935a"
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(training_images, training_labels),(testing_images, testing_labels) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_Lgse1mloXb",
        "outputId": "20cb2dfc-f354-4bf5-9866-e993daafc7da"
      },
      "source": [
        "print(\"The number of training images is {}\".format(training_images.shape[0]))\n",
        "print(\"The number of testing images is {}\".format(testing_images.shape[0]))\n",
        "print(\"The shape of an image is {}X{}\".format(training_images.shape[1],\n",
        "                                              training_images.shape[2]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The number of training images is 60000\n",
            "The number of testing images is 10000\n",
            "The shape of an image is 28X28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJYUk6GrlGmp"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "np.set_printoptions(linewidth=200)\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YboJdayulamy",
        "outputId": "f4a59c58-3939-4ead-9e94-db4706775359"
      },
      "source": [
        "img_number = random.randint(0, training_images.shape[0])\n",
        "plt.imshow(training_images[img_number])\n",
        "print(training_labels[img_number])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsFk7rY5mWpo"
      },
      "source": [
        "All of the pixels values are between 0 and 255. If we are training a neural network, for various reasons it's easier that all values are between 0 and 1.\n",
        "\n",
        "This can be done using `normalizing`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kb7d3LjcnB58"
      },
      "source": [
        "training_images  = training_images / 255.0\n",
        "testing_images = testing_images / 255.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUo8UBQHp_N4"
      },
      "source": [
        "# User Defined Callbacks\n",
        "Callbacks are used to control the training. For example, to stop the training once the desired metric reached a certain value.\n",
        "\n",
        "Here, we will define a callback to stop the training once the training accuracy reaches **98%**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLJf_l3JqouV"
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback\n",
        "\n",
        "class myCallback( Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('accuracy')>0.98):\n",
        "      print(\"\\nReached 98% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXQ0kOROnflN"
      },
      "source": [
        "# Defining the model using **Sequential** API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9rkDIjdngXM"
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56pQNcXJnoQu"
      },
      "source": [
        "model = Sequential([Flatten(input_shape=(28,28)), \n",
        "                    Dense(128, activation=tf.nn.relu), \n",
        "                    Dense(10, activation=tf.nn.softmax)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzAMbAzMtSWw",
        "outputId": "9133c4a1-e293-4678-c635-d57e7dedba27"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "flatten (Flatten)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 101,770\n",
            "Trainable params: 101,770\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmI9EO-8n9U4"
      },
      "source": [
        "Define the **optimizer** and the **loss**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVS9wyG9n_cE"
      },
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4m-li45MojR6"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94PtEBCwog6s"
      },
      "source": [
        "callbacks = myCallback() # user defined callback to stop the training once reach certain accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goeXHiZg9GZk"
      },
      "source": [
        "# define a call back to save model checkpoints \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# Create a callback that saves the model's weights\n",
        "# to save all checkpoints, uncomment the following lines\n",
        "#checkpoint_path = \"training_1/cp-{epoch:04d}.ckpt\"\n",
        "#cp_callback = ModelCheckpoint(filepath=checkpoint_path,\n",
        "#                                                 save_weights_only=True,\n",
        "#                                                 verbose=1)\n",
        "\n",
        "# Save only the check point with the best acc\n",
        "checkpoint_path = \"training_1/cp-best.ckpt\"\n",
        "cp_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_path,\n",
        "    save_weights_only=True,\n",
        "    monitor='accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5haywRVF9SRC",
        "outputId": "c1bb5c71-8293-4f57-8f96-ee829b257213"
      },
      "source": [
        "model.fit(training_images, training_labels, epochs=10, callbacks=[callbacks, cp_callback])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 5s 2ms/step - loss: 0.2534 - accuracy: 0.9275\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1132 - accuracy: 0.9664\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0793 - accuracy: 0.9763\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0589 - accuracy: 0.9822\n",
            "\n",
            "Reached 98% accuracy so cancelling training!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc4e088bdd0>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qQXQdWnolTu"
      },
      "source": [
        "Evaluate the model on the test images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nC_Ium0nooci",
        "outputId": "26f0ad73-f754-4c2c-af87-a84b234debd4"
      },
      "source": [
        "evaluation = model.evaluate(testing_images, testing_labels)\n",
        "print(\"Accuracy on the testing images is {}\".format(evaluation[1]*100))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9745\n",
            "Accuracy on the testing images is 97.45000004768372\n"
          ]
        }
      ]
    }
  ]
}